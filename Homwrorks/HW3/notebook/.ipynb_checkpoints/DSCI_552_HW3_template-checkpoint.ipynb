{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Author: \n",
    "## USC ID: \n",
    "## Github Userid: \n",
    "## Created Time: Feb 8, 2023"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Packages Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1.Time Series Classification Part 1: Feature Creation/Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### An interesting task in machine learning is classification of time series. In this problem, we will classify the activities of humans based on time series obtained by a Wireless Sensor Network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (a) Download the AReM data from: https://archive.ics.uci.edu/ml/datasets/Activity+Recognition+system+based+on+Multisensor+data+fusion+\\%28AReM\\%29 . The dataset contains 7 folders that represent seven types of activities. In each folder, there are multiple  les each of which represents an instant of a human performing an activity.1 Each  le containis 6 time series collected from activities of the same person, which are called avg rss12, var rss12, avg rss13, var rss13, vg rss23, and ar rss23. There are 88 instances in the dataset, each of which contains 6 time series and each time series has 480 consecutive values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (b) Keep datasets 1 and 2 in folders bending1 and bending 2, as well as datasets 1, 2, and 3 in other folders as test data and other datasets as train data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (c) Feature Extraction：Classification of time series usually needs extracting features from them. In this problem, we focus on time-domain features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ci. Research what types of time-domain features are usually used in time series classification and list them (examples are minimum, maximum, mean, etc)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ii. Extract the time-domain features minimum, maximum, mean, median, standard deviation,  rst quartile, and third quartile for all of the 6 time series in each instance. You are free to normalize/standardize features or use them directly. $^2$ Your new dataset will look like this:\n",
    "\n",
    "#### where, for example, 1st quart6, means the  rst quartile of the sixth time series in each of the 88 instances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### iii. Estimate the standard deviation of each of the time-domain features you extracted from the data. Then, use Python's bootstrapped or any other method to build a 90% bootsrap con dence interval for the standard deviation of each feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### iv. Use your judgement to select the three most important time-domain features (one option may be min, mean, and max)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2. ISLR 3.7.4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I collect a set of data (n = 100 observations) containing a single predictor and a quantitative response. I then fit a linear regression model to the data, as well as a separate cubic regression, i.e. $Y = \\beta_0 + \\beta_1 X + \\beta_2 X^2 + \\beta_3 X^3 + e$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a). Suppose that the true relationship between X and Y is linear, i.e. $Y = \\beta_0 + \\beta_1 X + e$. Consider the training residual sum of squares (RSS) for the linear regression, and also the training RSS for the cubic regression. Would we expect one to be lower than the other, would we expect them to be the same, or is there not enough information to tell? Justify your answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b). Answer (a) using test rather than training RSS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c). Suppose that the true relationship between X and Y is not linear, but we don’t know how far it is from linear. Consider the training RSS for the linear regression, and also the training RSS for the cubic regression. Would we expect one to be lower than the other, would we expect them to be the same, or is there not enough information to tell? Justify your answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### d). Answer (c) using test rather than training RSS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3. Extra Practice ISLR 3.7.3 & 3.7.5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ISLR 3.7.3 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose we have a data set with five predictors:\n",
    "> - $X_1$ = GPA\n",
    "> - $X_2$ = IQ\n",
    "> - $X_3$ = Level (1 for College and 0 for High School)\n",
    "> - $X_4$ = Interaction between GPA and IQ\n",
    "> - $X_5$ = Interaction between GPA and Level\n",
    "\n",
    "The response is starting salary after graduation (in thousands of dollars). Suppose we use least squares to fit the model, and get\n",
    "\n",
    "> - $\\hat{\\beta_{0}}$ = 50 \n",
    "> - $\\hat{\\beta_{1}}$ = 20\n",
    "> - $\\hat{\\beta_{2}}$ = 0.07\n",
    "> - $\\hat{\\beta_{3}}$ = 35 \n",
    "> - $\\hat{\\beta_{4}}$ = 0.01\n",
    "> - $\\hat{\\beta_{5}}$ = -10\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the given formular for salary:\n",
    "\\begin{equation}\n",
    "salary = \\beta_{0} + \\beta_{1} \\cdot GPA + \\beta_{2} \\cdot IQ + \\beta_{3} \\cdot Level + \\beta_{4} \\cdot (GPA \\cdot IQ) + \\beta_{5} \\cdot (GPA \\cdot Level)\n",
    "\\end{equation}\n",
    "\n",
    "and the beta from lease square method, we can get the final model as\n",
    "\\begin{equation}\n",
    "salary = 50 + 20 \\cdot GPA + 0.07 \\cdot IQ + 35 \\cdot Level + 0.01 \\cdot (GPA \\cdot IQ) -10 \\cdot (GPA \\cdot Level)\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (a) Which asnwer is correct, and why?\n",
    "> i. For a fixed value of IQ and GPA, high school graduates earn more, on average, than college graduates.  \n",
    "> ii. For a fixed value of IQ and GPA, college graduates earn more ,on average, than high school graduates.  \n",
    "> iii. For a fixed value of IQ and GPA, high school graduates earn more, on average, than college graduates provided that the GPA is high enough.  \n",
    "> iv. For a fixed value of IQ and GPA, college graduates earn more, on average, than college graduates provided that the GPA is high enough.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (b) Predict the salary of a college graduate with IQ of 110 and a GPA of 4.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (c) True or false: Since the coefficient ofor the GPA/IQ interaction term is very small, there is very little evidence of an interaction effect. Justify your answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ISLR 3.7.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the fitted values that result from performing linear regres- sion without an intercept. In this setting, the ith fitted value takes the form: $\\hat{y_{i}}$ = $x_i$ $\\hat{\\beta}$, where,\n",
    "\n",
    "$\\hat{\\beta} = (\\sum_{i=1}^{n}x_i y_i)/(\\sum_{i=1}^{n}$ x'$_i^2$).\n",
    "Show that we can write\n",
    "$\\hat{yi} = \\sum_{i'=1}^{n}$ a'$_i$y'$_i$\n",
    "\n",
    "What's a'$_i$?\n",
    "\n",
    "Note: We interpret this result by saying that the fitted values from linear regression are linear combinations of the response values.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q4. Time Series Classification Part 2 Binary and Multiclass Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Important Note: You will NOT submit this part with Homework 3. However, because it uses the features you extracted from time series data in Homework 3, and because some of you may want to start using your features to build models earlier, you are provided with the instructions of the next programming assignment. Thus, you may want to submit the code for Homework 3 with Homework 4 again, since it might need the feature creation code. Also, since this part involves building various models, you are strongly recommended to start as early as you can."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a) Binary Classification Using Logistic Regression $^3$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### i. Assume that you want to use the training set to classify bending from other activities, i.e. you have a binary classification problem. Depict scatter plots of the features you speci ed in 1(c)iv extracted from time series 1, 2, and 6 of each instance, and use color to distinguish bending vs. other activities. (See p. 129 of the textbook). $^4$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ii. Break each time series in your training set into two (approximately) equal length time series. Now instead of 6 time series for each of the training instances, you have 12 time series for each training instance. Repeat the experiment in 4(a)i, i.e depict scatter plots of the features extracted from both parts of the time series 1,2, and 6. Do you see any considerable difference in the results with those of 4(a)i?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### iii. Break each time series in your training set into $l \\in \\{1,2,...,20\\}$ time series of approximately equal length and use logistic regression $^5$ to solve the binary classification problem, using time-domain features. Remember that breaking each of the time series does not change the number of instances. It only changes the number of features for each instance. \n",
    "#### Calculate the p-values for your logistic regression parameters in each model corresponding to each value of l and refit a logistic regression model using your pruned set of features. $^6$\n",
    "#### Alternatively, you can use backward selection using sklearn.feature selection or glm in R. Use 5-fold cross-validation to determine the best value of the pair (l; p), where p is the number of features used in recursive feature elimination.\n",
    "#### Explain what the right way and the wrong way are to perform cross-validation in this problem. $^7$ Obviously, use the right way! #### Also, you may encounter the problem of class imbalance, which may make some of your folds not having any instances of the rare class. In such a case, you can use stratified cross validation. Research what it means and use it if needed.\n",
    "#### In the following, you can see an example of applying Python's Recursive Feature Elimination, which is a backward selection algorithm, to logistic regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Recursive Feature El imination\n",
    "#from sklearn import datasets\n",
    "#from sklearn.feature_selection import RFE\n",
    "#from sklearn.linearmodel import LogisticRegression\n",
    "## load the iris datasets\n",
    "#dataset = datasets.loadiris( )\n",
    "## create base classifier used to evaluate a subset of attributes\n",
    "#model = LogisticRegression( )\n",
    "## create the RFE model and select 3 attributes\n",
    "#rfe = RFE(model,3)\n",
    "#rfe = rfe.fit(dataset.data,dataset.target)\n",
    "## summarize the selection of the attributes\n",
    "#print(rfe.support)\n",
    "#print(rfe.ranking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### iv. Report the confusion matrix and show the ROC and AUC for your classifier on train data. Report the parameters of your logistic regression  $\\beta_i$'s as well as the p-values associated with them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### v. Test the classifier on the test set. Remember to break the time series in your test set into the same number of time series into which you broke your training set. Remember that the classifier has to be tested using the features extracted from the test set. Compare the accuracy on the test set with the cross-validation accuracy you obtained previously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### vi. Do your classes seem to be well-separated to cause instability in calculating logistic regression parameters?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### vii. From the confusion matrices you obtained, do you see imbalanced classes? If yes, build a logistic regression model based on case-control sampling and adjust its parameters. Report the confusion matrix, ROC, and AUC of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b) Binary Classification Using L1-penalized logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### i. Repeat 4(a)iii using $L_{2}$-penalized logistic regression, $^8$ i.e. instead of using p-values for variable selection, use $L_1$ regularization. Note that in this problem, you have to cross-validate for both l, the number of time series into which you break each of your instances, and  $\\lambda$, the weight of $L_1$ penalty in your logistic regression objective function (or $C$, the budget). Packages usually perform cross-validation for $\\lambda$  automatically. $^9$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ii. Compare the $L_1$-penalized with variable selection using p-values. Which one performs better? Which one is easier to implement?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (c) Multi-class Classification (The Realistic Case)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### i. Find the best l in the same way as you found it in 4(b)i to build an $L_1$-penalized multinomial regression model to classify all activities in your training set. $^{10}$ Report your test error. Research how confusion matrices and ROC curves are defined for multiclass classification and show them for this problem if possible. $^{11}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ii. Repeat 4(c)i using a Naive Bayes' classifier. Use both Gaussian and Multinomial priors and compare the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### iii. Which method is better for multi-class classification in this problem?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
